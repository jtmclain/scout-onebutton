<!doctype html>
<html lang="en">
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover" />
<title>Scout — Live Talk</title>
<style>
  :root { --fg:#0e0e10; --bg:#fff; --muted:#6b7280; --accent:#0b57d0; --chip:#eef2ff; --chipfg:#1e40af; }
  html,body{height:100%;margin:0;background:var(--bg);color:var(--fg);font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial}
  .wrap{min-height:100%;display:flex;flex-direction:column;align-items:center;justify-content:center;gap:20px;padding:20px}
  h1{font-size:18px;margin:0}
  .btn{width:min(520px,90vw);height:64px;border-radius:16px;background:var(--accent);color:#fff;border:0;font-size:18px}
  .btn:active{transform:scale(.99)}
  .chip{font-size:12px;padding:6px 10px;border-radius:999px;background:var(--chip);color:var(--chipfg)}
  .muted{color:var(--muted);font-size:12px}
  .log{width:min(640px,92vw);max-height:36vh;overflow:auto;border:1px solid #eee;border-radius:12px;padding:12px;font-size:14px;white-space:pre-wrap}
  .led{width:10px;height:10px;border-radius:50%;display:inline-block;margin-right:8px;background:#9ca3af}
  .led.listen{background:#22c55e}
  .led.think{background:#f59e0b}
  .led.speak{background:#0ea5e9}
</style>
<body>
  <!-- Hidden camera elements (no preview UI) -->
  <video id="cam" playsinline style="display:none"></video>
  <canvas id="snap" width="640" height="360" style="display:none"></canvas>

  <div class="wrap">
    <h1>Scout — Live Talk</h1>
    <div><span id="led" class="led"></span><span id="status" class="chip">Tap Start</span></div>
    <button id="toggle" class="btn">Start</button>
    <div id="log" class="log" aria-live="polite"></div>
    <div class="muted">One-button loop: Start → Speak naturally → pause → hear reply → keeps listening. Camera is used silently for a small snapshot per turn (if permission granted).</div>
  </div>

<script>
(() => {
  // ===== Config (tweak only if needed) =====
  const CAMERA_ENABLED = true;                  // keep true; if user denies, app continues without image
  const SNAP_W = 640;                           // snapshot width (JPEG ~0.6 quality)
  const VAD_RMS_THRESH = 0.015;                 // voice level threshold (~ -36 dBFS)
  const VAD_SILENCE_TAIL_MS = 500;              // end-turn silence window
  const VAD_MIN_TURN_MS = 600;                  // ignore clips shorter than this

  // ===== Elements & helpers =====
  const els = {
    toggle: document.getElementById('toggle'),
    status: document.getElementById('status'),
    log: document.getElementById('log'),
    led: document.getElementById('led'),
    cam: document.getElementById('cam'),
    snap: document.getElementById('snap')
  };
  const log = (s) => els.log.textContent = (els.log.textContent + (els.log.textContent?'\n':'') + s).slice(-4000);
  const setStatus = (s, mode) => { els.status.textContent = s; els.led.className = 'led ' + (mode||''); };

  // ===== Audio / VAD state =====
  let running=false, speaking=false, audioCtx, stream, source, processor, wakeLock;
  let buffers=[], collecting=false, sampleRate=48000;

  // ===== Camera state =====
  let cameraOn=false, camStream=null;

  // ===== Voice (pick best available) =====
  let preferredVoice=null;
  function chooseBestVoice() {
    const vs = speechSynthesis.getVoices();
    if (!vs || !vs.length) return;
    const by = (re)=>vs.find(v=>re.test(v.name));
    preferredVoice =
      by(/Siri.*(Voice|[0-9])/i) ||
      by(/Google US English/i)  ||
      by(/Google.*English/i)    ||
      vs.find(v=>/^en(-|_)?US/i.test(v.lang)) || vs[0];
    // console.log('[TTS] voice:', preferredVoice?.name, preferredVoice?.lang);
  }
  if (typeof speechSynthesis !== 'undefined') {
    speechSynthesis.onvoiceschanged = chooseBestVoice;
    setTimeout(chooseBestVoice, 300);
  }

  function speak(text) {
    try {
      window.speechSynthesis.cancel();
      const u = new SpeechSynthesisUtterance(String(text||''));
      u.rate = 1.0; u.pitch = 1.0; u.volume = 1.0;
      if (preferredVoice) u.voice = preferredVoice;
      speaking = true; setStatus('Speaking…','speak');
      u.onend = ()=>{ speaking=false; setStatus('Listening…','listen'); };
      speechSynthesis.speak(u);
    } catch {}
  }

  async function requestWakeLock() {
    try {
      if ('wakeLock' in navigator) {
        wakeLock = await navigator.wakeLock.request('screen');
        wakeLock.addEventListener('release', ()=>{});
      }
    } catch {}
  }

  // ===== Camera capture (silent, single frame) =====
  async function ensureCamera() {
    if (!CAMERA_ENABLED || cameraOn) return;
    try {
      camStream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode:'environment', width:{ideal:SNAP_W}, frameRate:{ideal:24,max:30} }, audio:false
      });
      els.cam.srcObject = camStream;
      await els.cam.play(); // hidden but needed to have a frame ready
      cameraOn = true;
    } catch (e) {
      log('Camera permission skipped (continuing without image).');
      cameraOn = false;
    }
  }
  function takeSnapshotBase64() {
    try {
      const vw = els.cam.videoWidth||SNAP_W, vh = els.cam.videoHeight||Math.round(SNAP_W*9/16);
      const h = Math.round(SNAP_W * (vh / vw));
      els.snap.width=SNAP_W; els.snap.height=h;
      els.snap.getContext('2d',{willReadFrequently:true}).drawImage(els.cam,0,0,SNAP_W,h);
      return els.snap.toDataURL('image/jpeg',0.6).split(',')[1];
    } catch { return null; }
  }

  // ===== VAD helpers =====
  function startCollect(){ buffers=[]; collecting=true; }
  function stopCollect(){ collecting=false; }
  function concatFloat32(chunks){ let len=0; for(const c of chunks) len+=c.length; const out=new Float32Array(len); let o=0; for(const c of chunks){ out.set(c,o); o+=c.length; } return out; }
  function rms(frame){ let s=0; for(let i=0;i<frame.length;i++){ const v=frame[i]; s+=v*v; } return Math.sqrt(s/frame.length); }

  // downsample 48k->16k and encode WAV (mono, 16-bit)
  function floatToWav16k(float32, srcRate=48000){
    const target=16000, ratio=srcRate/target, newLen=Math.floor(float32.length/ratio);
    const pcm16=new Int16Array(newLen);
    for(let i=0,j=0;j<newLen;j++,i+=ratio){
      const s=Math.max(-1,Math.min(1,float32[Math.floor(i)]||0));
      pcm16[j]=s<0?s*0x8000:s*0x7FFF;
    }
    const header=44, buf=new ArrayBuffer(header+pcm16.length*2), v=new DataView(buf);
    let o=0; const w4=x=>{v.setUint32(o,x,true);o+=4}, w2=x=>{v.setUint16(o,x,true);o+=2}, w1s=s=>{for(let i=0;i<s.length;i++)v.setUint8(o++,s.charCodeAt(i));};
    w1s('RIFF'); w4(36+pcm16.length*2); w1s('WAVE'); w1s('fmt '); w4(16); w2(1); w2(1); w4(target); w4(target*2); w2(2); w2(16);

